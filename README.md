# Overview
## 1 Description
This project is an **unofficial** Spring Boot starter for quick access to Open AI's API being developed and maintained by **[Cena Studio](https://www.cena.cool)**. Aiming to facilitate Spring Boot developers, this project is licensed under **[the MIT license](https://github.com/Cena-Studio/openai-spring-boot-starter/blob/main/LICENSE)**. In response to the characteristics of Spring Boot servers, this project has optimized the handling of concurrent requests and further encapsulated possible errors that requests may generate. In the future, this will be further enhanced according to the roadmap.

This project is currently established on Spring Boot 3.0.4. Broader version support will be provided based on feedback and demands from the community in the future. In the meantime, please make sure that your Spring Boot project version is compatible with this starter.

## 2 Development Roadmap
![roadmap](https://github.com/Cena-Studio/openai-spring-boot-starter/blob/main/assets/roadmap.png)

# Quick Start
## 1 Fundamental Steps
### 1.1 Import Package
For Maven project, please add the following dependency into your pom.xml:
```XML
<dependency>
	<groupId>org.springframework.boot</groupId>
	<artifactId>spring-boot-starter-web</artifactId>
	<version>x.x.x</version> <!-- set a specific version number -->
</dependency>
```
### 1.2 Configuration
Add records to the configuration file of a Spring Boot application as needed. The following is a very first yaml configuration file:
```yaml
openai:
    key: xx-xxxxxxxx    # *REQUIRED* your API key
    organization: xx-xxxxxxxx   # optional organization key. set a specific organization when you belong to several of them
```
In the configuration file, the `openai.key` is the one and only required field (so that OpenAI can ~~charge you for~~ offer their services). For advanced developers, this starter also provides more optional parameters based on the OpenAPI spec. The parameters available for each specific API will be listed in the following related sections. Or, you can refer to **[the application.yml template](https://github.com/Cena-Studio/openai-spring-boot-starter/blob/main/application.yml)** for a complete configuration example.
### 1.3 Autowiring
Use auto-wiring mechanism to load the OpenAISource bean in the classes wherever the request is needed. The following is an example for a service class:
```java
import cool.cena.openai.OpenAiSource;

@Service
public class MyService{

    @Autowired
    OpenAiSource openAiSource;

}
```
## 2 Text Completion
Text completion is a basic form of completion. A response will be generated to answer a prompt.
### 2.1 Usage
The following are the basic statements to request for a text completion in a service class:
```java
@Service
public class MyService{

    @Autowired
    OpenAiSource openAiSource;

    public String MyMethod(){
        
        // create a context for text completion
        OpenAiTextCompletionContext textCompletion = openAiSource.createTextCompletionContext();

        // make a request with the prompt "Which is the most famous tourist attraction in Glasgow"
        OpenAiTextCompletionResponseBody response = textCompletion.create("Which is the most famous tourist attraction in Glasgow");

        // retrieve the completion text "It is probably the Kelvingrove Art Gallery and Museum"
        String responseText = response.getChoices().get(0).getText();

        // return the completion text
        return responseText;
    }
}
```
The above `OpenAiTextCompletionResponseBody` instance is strictly encapsulated according to the OpenAPI spec, and the property names follow Java camel case conventions. You can use getters to retrieve any properties you need from the response. Since the completion text might be the most frequently fetched information, the response object offers a shortcut method for it:
```java
// retrieve the completion text using a short cut
String responseText = response.getText();

//// retrieve the second completion text if you request for multiple choices
String responseText = response.getText(1);
```
### 2.2 Request Parameters
A complete general configuration for initializing every text completion can be written in the configuration file as shown below:
```yaml
openai:
    key: xx-xxxxxxxx
    textCompletion:
        model: "text-davinci-003" # the model used for the completion
        suffix: "end" # the suffix that comes after a completion of inserted text
        maxTokens: 4096 # the maximum number of tokens generated by ai as a response completion.
        temperature: 1  # 0~2 decimal. degree of randomness in the output. more randomness with bigger value
        topP: 1 # another parameter controlling the randomness. OpenAi suggests not setting both temperature and topP simultaneously
        n: 1    # Number of candidate completions generated for a same prompt request
        stream: false   # *YET_NOT_SUPPORTED* if the completion responds as a Server-Sent-Event stream
        logprobs: 0 # Include the log probabilities on the most likely tokens, as well the chosen tokens.
        echo: false # Echo back the prompt in addition to the completion
        stop: ["bye", "ok"] # a list of at most 4 sequences where the API will stop generating further tokens.
        presencePenalty: 0  # -2~2 decemal. official explanation: https://platform.openai.com/docs/api-reference/parameter-details
        frequencyPenalty: 0 # -2~2 decemal.  official explanation: https://platform.openai.com/docs/api-reference/parameter-details
        bestOf: 0  # Generates best_of completions server-side and returns the best (the one with the highest log probability per token).
        logitBias: # -100~100 decimal. the likelihood of each specific token appears in the completion
            1965: 1.0   # the logit bias of token 1964 is 1.0.
            2023: -0.5  #  token 2023 is more unlikely to appear in the completion since its logit bias is negative.
        user: "cena"  # the user of the completion request
```
When using the service, the configuration of each single context instance can be dynamically customed whenever needed. An example is given below:
```java        
OpenAiTextCompletionContext textCompletionOne = openAiSource.createTextCompletionContext();
OpenAiTextCompletionContext textCompletionTwo = openAiSource.createTextCompletionContext();

// textCompletionOne and ...Two have same configurations when making requests

textCompletionOne.setMaxTokens("200");
textCompletionTwo.setEcho(true);

// now textCompletionOne and ...Two have different configurations
```
## 3 Chat Completion
A chat completion could be considered as a completion of a conversation context, which is also the core of ChatGPT. This starter offers a good management of the context by using a "message tree".
### 3.1 Simple Usage
Assuming the OpenAiSource has been autowired in a class and there is a "myMethod()" method inside that class, a simple way to create a chat completion based on the OpenAPI spec could be seen below:
```java
public void MyMethod(){

    // create a chat completion context for requests
    OpenAiChatCompletionContext chatCompletion = openAiSource.createChatCompletionContext();
    
    // add a single prompt to the context
    chatCompletion.addUserMessage("Which is the largest lake in scotland");
    
    // request for a chat completion with the prompt
    OpenAiChatCompletionResponseBody response = chatCompletion.create();

    // GPT responds you with message "The largest lake in Scotland is actually Loch Lomond."

}
```
The `OpenAiChatCompletionResponseBody` instance is strictly encapsulated according to the response body structure provided by OpenAI, and the property names follow Java camel case conventions. You can use getters directly to retrieve any properties you need from the instance. For example:
```java
// retrieve the message content "The largest lake in Scotland is actually Loch Lomond"
String messageContent = response.getChoices().get(0).getMessage().getContent();
// retrieve the token consumed by the prompt
int promptTokens = response.getUsage().getPromptTokens();
```
However, retrieving the message content using the above approach might be tedious. Alternatively, you may use a shortcut method provided by this starter:
```java
// retrieve the message content "The largest lake in Scotland is actually Loch Lomond" using a shortcut
String message = response.getMessage();
```
If we want to follow up on the topic and ask "what about the highest mountain". According to the context, GPT should respond with the highest mountain in Scotland instead of the highest one in the whole world. To manually realize such feature, we may use the following code (soon you will learn in Section 3.2 that there are much better ways to achieve this):
```java
// create a chat completion context for requests
OpenAiChatCompletionContext chatCompletion = openAiSource.createChatCompletionContext();

// add a single prompt to the context
chatCompletion.addUserMessage("Which is the largest lake in scotland")
    .addAssistantMessage("The largest lake in Scotland is actually Loch Lomond")
    .addUserMessage("What about the highest mountain?");

// request for a chat completion with the prompt
OpenAiChatCompletionResponseBody response = chatCompletion.create();

// GPT responds you with message "The highest mountain in Scotland is Ben Nevis."
```

### 3.2 Ongoing Context
Though the above example works, it looks stupid since everytime a complete prompt context has to be reconstructed from the beginning. Don't worry, the powerful support of this starter is just beginning to be shown to you.

This time let's make the same two requests about lakes and mountains again, but with another coding:
```java
OpenAiChatCompletionContext chatCompletion = openAiSource.createChatCompletionContext();

OpenAiChatCompletionResponseBody response = chatCompletion.create("Which is the largest lake in scotland");
System.out.println(response.getMessage());  // "The largest lake in Scotland is actually Loch Lomond."

response = chatCompletion.create("What about the highest mountain?");
System.out.println(response.getMessage());  // "The highest mountain in Scotland is Ben Nevis."
```
As can be seen, for each conversation (or chat room, in practical terms), only keeping a single `OpenAiChatCompletionContext` instance is needed. The context will help you manage the prompts of the conversation and even control the number of tokens consumed by the prompts during each request to prevent from the error from the OpenAi server that exceeding the max token limit.
### 3.3 Concurrent Requests
In practical, the user may send multiple messages in succession before receiving any response. OpenAI's pattern in its own ChatGPT is to prevent sending the next message before the previous one stops receiving a response. This requires more code in both frontend and Spring Boot application to block the user's messages, and if one response gets stuck, the conversation might be unable to proceed.

Let's see the following example and understand how this starter handle the relevant issue:
```java
@Service
public class MyService{

    Map<Integer, OpenAiChatCompletionContext> contextMap;  // just an example, assuming contexts of several conversations have been stored in a map

    public void MyMethod(int conversationId, String userMessage){
        
        OpenAiChatCompletionContext chatCompletion = contextMap.get(conversationId);
        // user send "Which is the largest lake in scotland" and triggered request_1
        // user send "What about the highest mountain?" and triggered request_2
        OpenAiChatCompletionResponseBody response = chatCompletion.create(userMessage);

        System.out.println(response.getMessage());  // "The largest lake in Scotland is Loch Lomond and the highest mountain in Scotland is Ben Nevis."

    }

}
```
With the above implementation, given that the user send "largest lake in scotland" and "the highest mountain" in succession so there will be two requests waiting for responses simultineously. Then, when the first response is received, it will be deprecated since it is outdated and an exception will be thrown. The second response, generated based on both the two user prompts, will give a complete reply.

Having this mechanism, other exceptions such as the HTTP exceptions caused by the network connection are also well solved. There is no need to use additional code in the project to prevent a series of subsequent problems caused by a single request response failure. However, if there is necessary logic that must be executed after the request, then the try-catch block can be used to catch the exception. To this end, the starter has also encapsulated the possible exceptions. For details please refer to **[the exception documentation](https://github.com/Cena-Studio/openai-spring-boot-starter/blob/main/exception.md)**.
### 3.3 Request Parameters
A complete general configuration for initializing every chat completion context can be written in the configuration file as shown below:
```yaml
openai:
    key: xx-xxxxxxxx
    chatCompletion:
        model: "gpt-3.5-turbo"    # the model used for the completion
        temperature: 1  # 0~2 decimal. degree of randomness in the output. more randomness with bigger value
        topP: 1 # another parameter controlling the randomness. OpenAi suggests not setting both temperature and topP simultaneously
        n: 1    # Number of candidate completions generated for a same prompt request
        stream: false   # *YET_NOT_SUPPORTED* if the completion responds as a Server-Sent-Event stream
        stop: ["bye", "ok"] # a list of at most 4 sequences where the API will stop generating further tokens.
        maxPromptToken: 3000    # the maximum number of tokens sourced from the preceding context that can be used for a request prompt.
        maxCompletionToken: 4096    # the maximum number of tokens generated by ai as a response completion.
        presencePenalty: 0 # -2~2 decemal. official explanation: https://platform.openai.com/docs/api-reference/parameter-details
        frequencyPenalty: 0 # -2~2 decemal. official explanation: https://platform.openai.com/docs/api-reference/parameter-details
        logitBias: # -100~100 decimal. the likelihood of each specific token appears in the completion
            1965: 1.0   # the logit bias of token 1964 is 1.0.
            2023: -0.5  #  token 2023 is more unlikely to appear in the completion since its logit bias is negative.
        user: "cena"  # the user of the completion request
```
When using the service, the configuration of each single context instance can be dynamically customed whenever needed. An example is given below:
```java
@Service
public class MyService{

    @Autowired
    OpenAiSource openAiSource;

    public void MyMethod(){
        
        // create two independent chat completion contexts
        OpenAiChatCompletionContext chatCompletionOne = openAiSource.createChatCompletionContext();
        OpenAiChatCompletionContext chatCompletionTwo = openAiSource.createChatCompletionContext();

        // chatCompletionOne and ...Two have same configurations when making requests

        chatCompletionOne.setModel("gpt-4");
        chatCompletionTwo.setTemperature("1.3");
        
        // now chatCompletionOne and ...Two have different configurations

    }

}
```
### 3.4 Choices
All the examples discussed so far are based on the default choices, i.e. n = 1. So, can this starter handle multiple choices? The answer is absolutely yes.
Let's make a request first:
```java
// create a context, set the request parameter n = 3 and make a request
OpenAiChatCompletionContext chatCompletion = openAiSource.createChatCompletionContext();
OpenAiChatCompletionResponseBody response = chatCompletion.setN(3).create("Is there a monster in Loch Ness?");
```
Now the response conains three choices:
```java
String messageContentOne = response.getChoices().get(0).getMessage().getContent();
String messageContentTwo = response.getChoices().get(1).getMessage().getContent();
String messageContentThree = response.getChoices().get(2).getMessage().getContent();

System.out.println(messageContentOne);  // "I don’t have personal beliefs..."
System.out.println(messageContentTwo);  // "I cannot prove or disprove..."
System.out.println(messageContentThree);    // "I cannot assert the existence..."
```
Or, fetch them by using the shorcut:
```java
String messageContentOne = response.getMessage();   // same as response.getMessage(0)
String messageContentTwo = response.getMessage(1);
String messageContentThree = response.getMessage(2);
```
Now there are three branches in the context. To continue with one of the branches:
```java
// switch the context to the second choice (index start from 0) and continue the conversation based on it
response = chatCompletion.setN(2).switchVersion(1).create("Got it. Thank you, GPT.");

//now you get two choices responding to the above request

// keep requesting without switch version
response = chatCompletion.create("Tell me a joke");
```
As demonstrated above, managing multiple choices is super concise with the strong support of this starter. But there could be two questions remained:
1. What if I don't switch version after getting a multiple choices response?
2. Supposing we've made several multiple-choices requests, each time we switch a choice and make the next request so the conversation goes further and further. What if we want to roll back to the 3-choices response for the very first request and choose another branch of it and extend another conversation?

For Question 1, if the context is not switched manually, it will by default adopts the first choice. Therefore, the last statement in the above code example equals to the following statement:
```java
response = chatCompletion.switchVersion(0).create("Tell me a joke");
```
For Question 2, even there is such a complicated requirement, this starter still support it by using the following implementation:
```java
// create a context
OpenAiChatCompletionContext chatCompletion = openAiSource.createChatCompletionContext();
// make the 1st request for a 3-choices response
OpenAiChatCompletionResponseBody response = chatCompletion.setN(3).create("Is there a monster in Loch Ness?");

// get the needed information from the response

// switch the context to the third choice and record that version
Version savedVersion = chatCompletion.switchVersion(2).getVersion();
// switch back to the second choice and make the 2nd request for a 2-choices response
response = chatCompletion.setN(2).switchVersion(1).create("Got it. Thank you, GPT.");

// get the needed information from the response

// the conversation goes further with the 3rd request
response = chatCompletion.create("Tell me a joke");

// get the needed information from the response

// roll back to the very early version
chatCompletionOne.switchVersion(savedVersion);
```
In one word, the only thing needed to be done for switching to an early version is to use the getVersion() method to take a snapshot of it.

Now we are almost at the end of the Chat Completion. But before that, there is a final important note about `switchVersion()`. Please see the final example below:
```java
// supposing the n value is set to 3 in the configuration file
// make the 1st request for a 3-choices response
OpenAiChatCompletionResponseBody response = chatCompletion.create("Is there a monster in Loch Ness?");

// save a early version
Version earlyVersion = chatCompletion.getVersion();


// make several requests
response = chatCompletion.create("Got it. Thank you, GPT.");
response = chatCompletion.create("Tell me a joke");
...
...

// save the latest version
Version latestVersion = chatCompletion.getVersion();

// there is no problem to roll back to the early version
chatCompletionOne.switchVersion(earlyVersion);

// ERROR because the latestVersion no longer exists
chatCompletionOne.switchVersion(latestVersion);
```
**ATTENTION** When rolling back to an early version, the child branches will be discarded to keep the context safe. Developers should be careful when switch to a version that is not the latest version of a branch.
## 4 Edit
This API will respond to you with your input text modified or corrected.
### 4.1 Usage
To create an edit request:
```java
@Service
public class MyService{

    @Autowired
    OpenAiSource openAiSource;

    public void MyMethod(){
        
        // create a context for edit
        OpenAiEditContext edit = openAiSource.createEditContext();

        // make a request with the oritginal text "What day of the wek is today?" and request for spelling mistake fixes.
        OpenAiEditResponseBody response = edit.create("What day of the wek is today?", "fix the spelling mistakes");

        // get the fixed text and print it "What day of the week is today?"
        System.out.println(response.getChoices().get(0).getText());

    }

}
```
There is also a shortcut for retrieving the text from the response:
```java
// get the edited text with a shortcut
response.getText();

// pass the index in case of multiple choices to get the specific edited text with a shortcut
response.getText(1);
```
### 4.2 Request Parameters
A general configuration for image generation context could be written in the configuration file before the application launched:
```yaml
openai:
    key: xx-xxxxxxxx
    edit:
        model: "text-davinci-edit-001"    # the model used for the task
        temperature: 1  # 0~2 decimal. degree of randomness in the output. more randomness with bigger value
        topP: 1 # another parameter controlling the randomness. OpenAi suggests not setting both temperature and topP simultaneously
        n: 1    # Number of candidate editss generated for a request
```
The configuration of each single context instance can be dynamically changed. An example is given below:
```java
// create two independent edit contexts
OpenAiEditContext editOne = openAiSource.createEditContext();
OpenAiEditContext editTwo = openAiSource.createEditContext();

// editOne and ...Two have same configurations when making requests

editOne.setN("2").setModel("text-davinci-edit-001");
editTwo.setTopP(0.8);

// now editOne and ...Two have different configurations
```
## 5 Moderation
Moderation might be an important API to classify if the input texts are violative.

The following are the example implementation for making a request:
```java
@Service
public class MyService{

    @Autowired
    OpenAiSource openAiSource;

    public void MyMethod(){
        
        // create a context for moderation
        OpenAiModerationContext moderation = openAiSource.createModerationContext();

        // make a request with the input "I want to beat my neighbours" (the author has very kind neighbours so this is just an example)
        OpenAiModerationResponseBody response = moderation.create("I want to beat my neighbours");

        boolean flag = response.getResults().get(0).isFlagged();
        double sexual = response.getResults().get(0).getCategoryScores().get("sexual"); // instead of getSexual() here
        boolean violence = response.getResults().get(0).getCategories().get("violence");

        System.out.println(flag);   // output true
        System.out.println(sexual); // output 8.516480011167005E-5
        System.out.println(violence);   // output true

    }

}
```
The above `OpenAiModerationResponseBody` instance is strictly encapsulated according to the OpenAPI spec, and the property names follow Java camel case conventions. A small difference is that the contents of categories and categoryScores are encapsulated into maps for intuitiveness and traversal. Shortcuts are as well offered for those main data:
```java
// retrieve the flag using a short cut
boolean flag = response.isFlagged();

// retrieve the score of sexual possibility using a short cut
Double sexual = response.getScoreResults("sexual");

// retrieve the judgement of violence possibility using a short cut
boolean violence = response.getBooleanResults("violence");
```
## 6 Image Generation
This API can synthesize pictures based on a given prompt.
### 6.1 Usage
To use this API with this starter:
```java
@Service
public class MyService{

    @Autowired
    OpenAiSource openAiSource;

    public void MyMethod(){
        
        // create a context for image generation
        OpenAiImageGenerationContext imageGeneration = openAiSource.createImageGenerationContext();

        // make a request with the prompt "A highland cattle drinking whisky"
        OpenAiImageGenerationResponseBody response = imageGeneration.create("A highland cattle drinking whisky");

        // get and print the image url
        System.out.println(response.getData().get(0).get("url"));

    }

}
```
OpenAi supports two formats of images in the response body. By default it gives a image url (like the above example). If the request parameter is set to `format: b64_json`, please use the statement below to get the responded image. The details of the request parameters will soon be discussed in Section 5.2.
```java
// get and print the base64 string of the image
System.out.println(response.getData().get(0).get("b64_json"));
```
However, it looks tedious to completely follow the structure of the response body to get a image. So, this starter provides shortcuts for it:
```java
// get the image with shortcut no matter the format
String image = response.getImage();
```
Note that it is not necessary to specify the format by using this shortcut. It will return a string of either image url or base64 depending on the request.

In addition, OpenAi also supports generating multiple images as choices for one single request, which is also supported by the shorcut:
```java
// get the second choice of a base64 image based on OpenAPI response structure
image = response.getData().get(1).get("b64_json");

// get the second choice of the images with shortcut no matter the format
image = response.getImage(1);
```
### 6.2 Request Parameters
A general configuration for image generation context could be written in the configuration file before the application launched:
```yaml
openai:
    key: xx-xxxxxxxx
    imageGeneration:
        n: 1    # number of candidate images generated for a request
        size: "1024x1024"  # the size of the image.
        response_format: "url"  # the format of the image in the response.
        user: "cena"  # the user of the completion request
```
The configuration of each single context instance can be dynamically customed. An example is given below:
```java
@Service
public class MyService{

    @Autowired
    OpenAiSource openAiSource;

    public void MyMethod(){
        
        OpenAiImageGenerationContext imageGenerationOne = openAiSource.createImageGenerationContext();
        OpenAiImageGenerationContext imageGenerationTwo = openAiSource.createImageGenerationContext();

        // imageGenerationOne and ...Two have same configurations when making requests

        imageGenerationOne.setN("2");
        imageGenerationTwo.setSize("256x256");
        
        // now imageGenerationOne and ...Two have different configurations

    }

}
```
## 7 Image Edit
This API can edit an existing image based on a given prompt and a mask image.
### 7.1 Usage
This API requires image files as request parameters. This starter aim to support different type of input parameters to represent the image file. Currently, it support `String` in base64 format, `String` of the local file path, `String` of the url of a remote image, `File`, `byte[]`, `SystemFileResource`, and `ByteArrayResource`. When an valid `String` argument is passed into the `create()` method, it will be automatically recognized and processed by this starter for making the request. Please see the example below:
```java
@Service
public class MyService{

    @Autowired
    OpenAiSource openAiSource;

    public void MyMethod(){
        
        // create a context for image generation
        OpenAiImageEditContext imageEdit = openAiSource.createImageEditContext();

        // a remote image resouce
        String imagePath = "https://www.***.com/sky.png";
        // make a request with a sky image and the prompt "add a bird"
        OpenAiImageEditResponseBody response = imageEdit.create(imagePath, "add a bird");

        // a local mask image
        String maskPath = "src/main/resources/static/mask.png";
        // make the request with the original image, the prompt, and the mask image
        OpenAiImageEditResponseBody responseWithMask = imageEdit.create(imagePath, "add a bird"， maskPath);

    }

}
```
The response body of the image edit API has the same structure as the image generation. An shortcut to retrieve the image is also provided:
```java
// get the base64 string of the image
response.getData().get(0).get("b64_json");

// get the image with shortcut no matter the format
response.getImage();

// get the second image if multiple images are generated
response.getImage(1);
```
**ATTENTION** Due to limitations of the OpenAI API, the original image used for a request must be a png file with a square size, i.e. height = width. Besides, it must be in one of RGBA (rgb with alpha channel), LA (grayscale with alpha channel), L (grayscale) formats. This starter aims to provide a broader support in a future update.
### 7.2 Request Parameters
The available configuration parameters for the image edit context is the almost same as the image generation context in Section 5.2. The only difference is the `imageEdit` is written to specify the configurations inside belongs to the image edit context.
```yaml
openai:
    key: xx-xxxxxxxx
    imageEdit:
        ... # parameters
```
## 8 Image Variation
This API can create different variations of an existing image.
### 8.1 Usage
This API has a very similar request body as image edit. The difference is that there is no prompt and mask parameters. The implementation could be down as shown below: 
```java
@Service
public class MyService{

    @Autowired
    OpenAiSource openAiSource;

    public void MyMethod(){
        
        // create a context for image generation
        OpenAiImageVariationContext imageVariation = openAiSource.createImageVariationContext();

        // a remote image resouce
        String imagePath = "https://www.***.com/sky.png";
        // make a request with a sky image
        OpenAiImageVariationResponseBody response = imageVariation.create(imagePath);

    }

}
```
The response body of the image edit API has the same structure as the image generation. An shortcut to retrieve the image is also provided:
```java
// get the base64 string of the image
response.getData().get(0).get("b64_json");

// get the image with shortcut no matter the format
response.getImage();

// get the second image if multiple images are generated
response.getImage(1);
```

### 8.2 Request Parameters
The available configuration parameters for the image edit context is the almost same as the image generation context in Section 5.2. The only difference is the `imageVariation` is written to specify the configurations inside belongs to the image edit context.
```yaml
openai:
    key: xx-xxxxxxxx
    imageVariation:
        ... # parameters
```
## 9 Embedding
This API can transfer the input text to a vector representation.
### 9.1 Usage
To create an embedding request:
```java
@Service
public class MyService{

    @Autowired
    OpenAiSource openAiSource;

    public void MyMethod(){
        
        // create a context for embedding
        OpenAiEmbeddingContext embedding = openAiSource.createEmbeddingContext();

        // make a request
        OpenAiEmbeddingResponseBody response = embedding.create("Create embedding for this input");

        // get the needed information from the response
        List<Double> embeddingData =  response.getData().get(0).getEmbedding();

    }

}
```
As shown above, the processed text will be responded as a group of decimals. There is also a shortcut for easier retrieving that decimal list from the response:
```java
// get the embedding list with a shortcut
response.getEmbedding();
```
In the original response body of this API, although the value of `data` parameter is an array, there is actually no multiple choices for this API since there is always only one element inside which contains the vector list.
### 9.2 Request Parameters
A general configuration for image generation context could be written in the configuration file before the application launched:
```yaml
openai:
    key: xx-xxxxxxxx
    embedding:
        model: "text-embedding-ada-002" # the model for the task
        user: "cena"  # the user of the completion request
```
The configuration of each single context instance can be dynamically changed. An example is given below:
```java
// create two independent embedding contexts
OpenAiEmbeddingContext embeddingOne = openAiSource.createEmbeddingContext();
OpenAiEmbeddingContext embeddingTwo = openAiSource.createEmbeddingContext();

// embeddingOne and ...Two have same configurations when making requests

embeddingOne.setN("2").setModel("text-davinci-embedding-001");
embeddingTwo.setTopP(0.8);

// now embeddingOne and ...Two have different configurations
```
## 10 Audio Transcription
By giving a valid audio file, this API can generate a corresponding transcription.
### 10.1 Usage
The file support is same as in Section 7.1, which including `String` in base64 format, `String` of the local file path, `String` of the url of a remote image, `File`, `byte[]`, `SystemFileResource`, and `ByteArrayResource`. When using an valid `String` as the argument, the type will be automatically recognized and processed.

The following is an example for making an audio transcription request:
```java
@Service
public class MyService{

    @Autowired
    OpenAiSource openAiSource;

    public void MyMethod(){
        
        // create a context for audio transcription
        OpenAiAudioTranscriptionContext audioTranscription = openAiSource.createAudioTranscriptionContext();

        // make a request with a local file path
        OpenAiAudioTranscriptionResponseBody response = audioTranscription.create("src/main/resources/static/audio.mp3");

        // get the transcription text and print it
        System.out.println(response.getText());

    }

}
```
For this api, it is concise enough to get the transcription text without any shortcuts.

In addition to only pass in the file, OpenAI also recommends to give it a prompt to describe the audio for more accurate transcription:
```java
// add a prompt for the request
OpenAiAudioTranscriptionResponseBody response = audioTranscription.create("src/main/resources/static/audio.mp3", "it is a speech text about GPT.");
```
Besides the above basic usage, OpenAi also provided different response text format based on the context configuration (the details of the context configuration will soon be discussed in Section 10.2). Currently this starter will not write the valid format of response text, such as srt format, into a file, so that you may do it manually after retrieving them as a String.

For another special response format, which is verbose_json that contains more metadata, it is completely supported by this starter. The following is the response body structure of this format:
```json
{
    task: String,
    language: String,
    duration: Double,
    segments: [
        {
            id: Integer,
            seek: Integer,
            start: Double,
            end: Double,
            text: String,
            tokens: List<Integer>,
            tremperature: Double,
            avgLogProb: Double,
            compressionRatio: Double,
            noSpeechProb: Double,
            trans: Boolean
        }
    ],
    text: String,
}
```
You can use the getters to retrieve the needed data. E.g. get the compression ratio:
```java
// get the compression ratio from the verbose_json response
Double compressionRatio = response.getSegments().get(0).getCompressionRatio();
```
### 10.2 Request Parameters
A general configuration for audio transcription context could be written in the configuration file before the application launched:
```yaml
openai:
    key: xx-xxxxxxxx
    audioTranscription:
        model: "whisper-1"  # the model for audio tasks. There is no alternative choices although OpenAi provided this parameter.
        responseFormat: "json"  # the format of the generated transcription text.
        language: "en" # language in ISO-639-1 format.
        temperature: 0 # 0~1 decimal. degree of randomness in the output. more randomness with bigger value.
```
Note that "whisper-1" is the only model could be used for this API, OpenAi just opens this parameter though.

The configuration of each single context instance can be dynamically changed. An example is given below:
```java
// create two independent audioTranscription contexts
OpenAiAudioTranscriptionContext audioTranscriptionOne = openAiSource.createAudioTranscriptionContext();
OpenAiAudioTranscriptionContext audioTranscriptionTwo = openAiSource.createAudioTranscriptionContext();

// audioTranscriptionOne and ...Two have same configurations when making requests

audioTranscriptionOne.setLanguage("zh");
audioTranscriptionTwo.setResponseFormat("vtt");

// now audioTranscriptionOne and ...Two have different configurations
```
## 11 Audio Translation
This API is simillar to audio transcription but translate the input audio into english transcription.
### 11.1 Usage
The following is an example for making an audio translation request:
```java
@Service
public class MyService{

    @Autowired
    OpenAiSource openAiSource;

    public void MyMethod(){
        
        // create a context for audio transcription
        OpenAiAudioTranslationContext audioTranslation = openAiSource.createAudioTranslationContext();

        // make a request with a local file path
        OpenAiAudioTranslationResponseBody response = audioTranslation.create("src/main/resources/static/audio.mp3");

        // get and print the translated text
        System.out.println(response.getText());

    }

}
```
Like audio transcription, you can also give prompt for translation.
```java
// add a prompt for the request
OpenAiAudioTranslationResponseBody response = audioTranslation.create("src/main/resources/static/audio.mp3", "it is a speech text about GPT.");
```
This API also supports the same response format as audio transcription with the same response body structrue.
### 11.2 Request Parameters
The configuration support for audio translation is also quite simillar to audio transcription but there is no `language` parameter.
```yaml
openai:
    key: xx-xxxxxxxx
    audioTranslation:
        model: "whisper-1"  # the model for audio tasks. There is no alternative choices although OpenAi provided this parameter.
        responseFormat: "json"  # the format of the generated transcription text.
        temperature: 0 # 0~1 decimal. degree of randomness in the output. more randomness with bigger value.
```