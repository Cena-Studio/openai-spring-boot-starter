# Overview
## 1 Description
This project is an **unofficial** Spring Boot starter for quick access to Open AI's API being developed and maintained by **[Cena Studio](https://www.cena.cool)**. Aiming to facilitate Spring Boot developers, this project is licensed under **[the MIT license](https://github.com/Cena-Studio/openai-spring-boot-starter/blob/main/LICENSE)**. In response to the characteristics of Spring Boot servers, this project has optimized the handling of concurrent requests and further encapsulated possible errors that requests may generate. In the future, this will be further enhanced according to the roadmap.

This project is currently established on Spring Boot 3.0.4. Broader version support will be provided based on feedback and demands from the community in the future. In the meantime, please make sure that your Spring Boot project version is compatible with this starter.

## 2 Development Roadmap
- Chat Completion ```<- current stage```
- Text Completion
- Moderation
- Image Generation
- HTTP Connection Configuration
- Other APIs

# Quick Start
## 1 Basic Preparation
### 1.1 Import Package
For Maven project, please add the following dependency into your pom.xml:
```XML
<dependency>
	<groupId>org.springframework.boot</groupId>
	<artifactId>spring-boot-starter-web</artifactId>
	<version>x.x.x</version> <!-- set a specific version number -->
</dependency>
```
### 1.2 Configuration
Add records to the configuration file of a Spring Boot application as needed. The following is an example of a yaml configuration file:
```yaml
openai:
    key: xx-xxxxxxxx    # *REQUIRED* your API key
    chatCompletion:
        model: gpt-3.5-turbo # optional. By default it is set to gpt-3.5-turbo to ensure that you are qualified to establish an effective connection.
        maxPromptToken: 2048 # optional. The maximum number of tokens sourced from the preceding context that can be used for a request prompt.
        maxCompletionToken: 4096 # optional. The maximum number of tokens generated by ai as a response completion.
```
As you may have noticed from the above example, the "key" is the one and only required field (so that OpenAI can ~~charge you for~~ offer their services). And certainly, for advanced developers, this starter also provides more optional parameters based on the OpenAPI spec. Please refer to **[the application.yml template](https://github.com/Cena-Studio/openai-spring-boot-starter/blob/main/application.yml)** for a complete configuration example.
### 1.3 Autowiring
Use auto-wiring mechanism to load the OpenAISource bean in the classes wherever the request is needed. The following is an example for a service class:
```java
import cool.cena.openai.OpenAiSource;

@Service
public class MyService{

    @Autowired
    OpenAiSource openAiSource

}
```
## 3 Chat Completion
A chat completion could be seen as a completion of a conversation context, which is also the core of ChatGPT. This starter offers a good management of the context by using a "message tree".
### 3.1 Basic Usage
Assuming the OpenAiSource has been autowired in a class and there is a "myMethod()" method inside that class, a simple way to create a chat completion based on OpenAPI spec could be seen below:
```java
public void MyMethod(){

    // create a chat completion context for requests
    OpenAiChatCompletionContext chatCompletion = openAiSource.createChatCompletionContext();
    
    // request for a chat completion with a message "Hello GPT"
    OpenAiChatCompletionResponse chatCompletionResponse = chatCompletion.create("Hello GPT");

    // GPT responds you with message "Hi, what can I do for you?"

}
```
The `OpenAiChatCompletionResponse` instance is strictly encapsulated according to the response body structure provided by OpenAI, and the property names follow Java camel case conventions. You can use getters directly to retrieve any properties you need from the instance. For example:
```java
    // retrieve the message content "Hi, what can I do for you?"
    String messageContent = chatCompletionResponse.getChoices().get(0).getMessage().getContent();
    // retrieve the token consumed by the prompt
    int promptTokens = chatCompletionResponse.getUsage().getPromptTokens();
```
However, retrieving the message content using the above approach might be tedious. Alternatively, you may use a shortcut method provided by this starter:
```java
    // retrieve the message content "Hi, what can I do for you?" using a shortcut
    String message = chatCompletionResponse.getMessage();
```

